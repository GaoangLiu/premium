batch_size: 32
epochs: 1
max_length: 128
model_name: bert-base-uncased
model_path: /tmp/nerbert.pt
learning_rate: 5.0e-3
